{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AML - Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhhBaqkKqjZo"
      },
      "source": [
        "### Week 2: Neural Network Architectures: CNN and Training Nets \n",
        "```\n",
        "- Advanced Machine Learning, Innopolis University \n",
        "- Professor: Muhammad Fahim \n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "\n",
        "```\n",
        "Lab Plan\n",
        "\n",
        "0. Previous Lab discussion & comments\n",
        "1. Loading of dataset\n",
        "2. Simple CNN model\n",
        "3. Training Simple CNN Model (Classification Task)\n",
        "4. Transfer Learning for CNN\n",
        "5. Model Comparision\n",
        "6. Lab Task\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow7g9qtXIX4M"
      },
      "source": [
        "## Load data and preprocess\n",
        "\n",
        "To load our data set (CIFAR10) we can either download it manualy or use torchvision package. `torchvision` consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
        "\n",
        "\n",
        "For smooth training of the CNN we need to transform (normalize) the images. `transforms` package conatains common image transformations. Image transformations can be chained together using `transforms.Compose`. In our case we need to first convert image to tensor `transforms.ToTensor()` then normalize `transforms.Normalize`\n",
        "\n",
        "The packages can be pip installed<br>\n",
        "`!pip install torch` <br>\n",
        "`!pip install torchvision`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VJrC_VUDxRp"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuno_RF7Chcs"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJWi9_mUIX4N"
      },
      "source": [
        "## Data visualization \n",
        "Create a simple method to have a look at the data (image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fuW-LQ6sNcd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jixrn6F_IX4O"
      },
      "source": [
        "## Lets Switch to the GPU (if available) - why?\n",
        "\n",
        "\n",
        "Unlike TensorFlow, PyTorch doesn’t have a dedicated library for GPU users,so its neccessary to some manual setup <br>\n",
        "<b>NB: </b>If working on Colab, make sure that GPU runtime is enabled <br>\n",
        "<b>NB: </b>It’s not possible to transfer Data Loaders directly to GPU <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2MaoD1sxB5"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0em82fIX4O"
      },
      "source": [
        "## Create a Simple Convolutional neural network (CNN)\n",
        "\n",
        "The simple CNN is made up of 2D Convolutional layers, Pooling layers and fully connected layers. <br> \n",
        "<b>NB : </b> If we succesfully connected to GPU, we need to send our CNN model to GPU for faster training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfKsfL1asNWD"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEwpKvC-IX4P"
      },
      "source": [
        "## CNN training \n",
        "\n",
        "What are the steps for training a neural network? \n",
        "<br> How do we send the data to training device (i.e GPU) durring the training process? Remember we train using batches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80_zxKUHuEMe"
      },
      "source": [
        "import torch.optim as optim\n",
        "def train_evaluate(net):\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "    # print images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    plt.show()\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = net(images).cuda()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                                for j in range(4)))\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(4):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUR3S5btIX4Q"
      },
      "source": [
        "## Simple CNN training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HBscgMqsQaY"
      },
      "source": [
        "train_evaluate(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aGGZIq2IX4Q"
      },
      "source": [
        "## CNN from popular model architectures (Transfer learning)\n",
        "\n",
        "Same procedure as simple CNN but the achitecture of the neural net is much more complicated and the weights are pretrained. <br> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w52dhIy5GTV3"
      },
      "source": [
        "### Fine Tuning\n",
        "Fine tuning or transfer learning is the task of training a model on a big dataset and then adjucting the parameters of the model for a smaller task with less data.\n",
        "\n",
        "It is very common in Computer Vision and Natural Language Processing with the immergence of BERT and UMLfit. \n",
        "![](https://miro.medium.com/max/1276/1*ZkPBqU8vx2vAgcLpz9pi5g.jpeg)\n",
        "\n",
        "Say we want to use resnet (trained on imagenet with 1000 classes and has input shape of 256x256)  and fine-tune it for CIFAR10 (has 10 categories with input shape of 32×32)\n",
        "\n",
        "What is the biggest changes that we need to make?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo0cX2koIX4R"
      },
      "source": [
        "## How to Import Popular CNN models? \n",
        "\n",
        "`torchvision,models` contains of popular model architectures and can be loaded together with their trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrL_UQgJChia"
      },
      "source": [
        "import torchvision.models as models\n",
        "resnet18 = models.resnet18(pretrained=True,progress=True)\n",
        "alexnet = models.alexnet(pretrained=True,progress=True)\n",
        "squeezenet = models.squeezenet1_0(pretrained=True,progress=True)\n",
        "vgg16 = models.vgg16(pretrained=True,progress=True)\n",
        "densenet = models.densenet161(pretrained=True,progress=True)\n",
        "inception = models.inception_v3(pretrained=True,progress=True)\n",
        "googlenet = models.googlenet(pretrained=True,progress=True)\n",
        "shufflenet = models.shufflenet_v2_x1_0(pretrained=True,progress=True)\n",
        "mobilenet = models.mobilenet_v2(pretrained=True,progress=True)\n",
        "resnext50_32x4d = models.resnext50_32x4d(pretrained=True,progress=True)\n",
        "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True,progress=True)\n",
        "mnasnet = models.mnasnet1_0(pretrained=True,progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9FN3guKIX4R"
      },
      "source": [
        "## Start by loading and transforming the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flbDSzpyv9pH"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((256,256)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_InhxFBIX4S"
      },
      "source": [
        "## Define CNN model \n",
        "\n",
        "<b>NB : </b>To make the model achitecture fit our classification task, we will change the last fully connected layer and train only it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdGA8DMKIX4S"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = models.resnet18(pretrained=True,progress=True)\n",
        "        self.net.trainable = False\n",
        "        self.net.fc = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_PanroIX4S"
      },
      "source": [
        "## Train and Evaluate the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATbxneSAy37R"
      },
      "source": [
        "train_evaluate(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeXDOSa41Rm"
      },
      "source": [
        "\n"
      ]
    }
  ]
}