{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "horizontal-cylinder",
   "metadata": {
    "id": "burning-productivity"
   },
   "source": [
    "## <center>Midterm Lab\n",
    "```\n",
    "- Advanced Machine Learning, Innopolis University \n",
    "- Professor: Muhammad Fahim \n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "```\n",
    "Tasks:\n",
    "  1. Image Transform (5 points)\n",
    "  2. CNN model declaration (10 points)\n",
    "  3. CNN model training (5 points)\n",
    "  4. Transfer Learning or Viterbi algorithm : Bonus (5 points)\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-demonstration",
   "metadata": {
    "id": "purple-diana"
   },
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-phase",
   "metadata": {
    "id": "yellow-arena"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-funeral",
   "metadata": {
    "id": "hazardous-excess"
   },
   "source": [
    "## Task 1 : Preprocessing of Dataset (5 points)\n",
    "\n",
    "1.   Create the transforms:\n",
    "    * Resize images to (32 * 32)\n",
    "    * Normalize every channel (mean and std of your choice)\n",
    "    * Apply one more data augmentation technique you know (i.e Rotation, translation, RandomErasing, RandomHorizontalFlip etc.)\n",
    "\n",
    "\n",
    "**Hint**: data augmentation techniques shouldn't be applied to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-acrobat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixJmk0lxhzUr",
    "outputId": "de6c1598-4de6-4f63-8b46-e239c08e94c3"
   },
   "outputs": [],
   "source": [
    "transform_train = None\n",
    "\n",
    "transform_test = None \n",
    "\n",
    "trainset = torchvision.datasets.SVHN(root='./data/train', split=\"train\", download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.SVHN(root='./data/test', split=\"test\", download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = [f\"{i}\" for i in np.unique(trainset.labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-performance",
   "metadata": {
    "id": "pTh7HB65ojmO"
   },
   "source": [
    "## Task 1.1 Plot Classes distribution \n",
    "\n",
    "Plot the distribution of classes in the training sample on a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-fourth",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "WnfHoErCmQk7",
    "outputId": "ea4e3d46-630f-4449-84d1-a759d90e55d5"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#TODO: Plot the distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-chicken",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "numerical-dependence",
    "outputId": "9a9dbbea-8b94-4173-89d1-938a2909bd06"
   },
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 3, 32, 32)\n",
    "    return x\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# sample a batch and show \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-humor",
   "metadata": {
    "id": "talented-welsh"
   },
   "source": [
    "## Task 2 : Build a classisfication convolutional neural network\n",
    "\n",
    "\n",
    "The Model should should have the following achitecture : \n",
    "1. 3 Convolution layers : (5 points)\n",
    "    * conv1 : 2 kernels, 3*3 kernel size, stride 1.\n",
    "    * conv2 : 4 kernels, 5*5 kernel size, stride 2.\n",
    "    * conv3 : 8 kernels, 3*3 kernel size, stride 1.\n",
    "    * Add 1 Avarage pooling layer after 2nd layer and 1 Max-pooling layer before the fully connected layers.\n",
    "    * Stride for all pooling operations set to 1 \n",
    "    \n",
    "    \n",
    "2. Fully connected layers : \n",
    "    * fc1 : 64 output-neurons with a relu activation.\n",
    "    * output_layer : final layer with no activation function\n",
    "    * Add Dropout layer after the first (fc1) layer with 25% dropout probability\n",
    "\n",
    "3. Implement the foward pass method for the CNN  (5 points)\n",
    "    * Add an activation function of your own choice after every layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-restaurant",
   "metadata": {
    "id": "pointed-trigger"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #TODO: Declare the model layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        \n",
    "        return #None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-occupation",
   "metadata": {
    "id": "metallic-delicious"
   },
   "source": [
    "## Task 3 : Convolutional neural network training precedure (5 points)\n",
    "\n",
    "Implement the model training procedure and select the appropriate loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-disposition",
   "metadata": {
    "id": "brutal-greensboro"
   },
   "outputs": [],
   "source": [
    "# Model accuracy calculator \n",
    "def accuracy_calc(net,testloader,device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-radio",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0XxmxSIKSp7",
    "outputId": "92048b96-ddcd-445e-ac37-da34d02f282e"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-typing",
   "metadata": {
    "id": "handmade-lesbian"
   },
   "outputs": [],
   "source": [
    "#Set hyper parameters \n",
    "nb_epoch = 3\n",
    "lr = 0.001\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "criterion = None #TODO: Define the Loss function (criterion)\n",
    "\n",
    "def train(model,trainloader,optimizer, criterion, device):\n",
    "    #TODO : Implement the training procedure of the model at each an every epoch. It should return model loss and accuracy on training sample\n",
    "    \n",
    "    return None , None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-purple",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "effective-silence",
    "outputId": "e728b1b1-2612-48c0-b414-1fe4f767450a"
   },
   "outputs": [],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    epochLoss, epochAcc = train(model,trainloader, optimizer, criterion, device)\n",
    "    print(f\"Epoch : {epoch}, Loss {epochLoss}, Accuracy {epochAcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-dodge",
   "metadata": {
    "id": "foster-notice"
   },
   "source": [
    "## Task 4 (bonus) : Use pretrained CNN model or Viterbi implementation (5 points)\n",
    "\n",
    "**Option 1** : Import any pretrained model and train on CIFAR10. Print out the loss and accuracy at each an every epoch. Number of training epochs and optimizer are of your choice. <br>\n",
    "**OPtion 2** : Implement the viterbi algorithm (from previous lab task POS tagging) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-statement",
   "metadata": {
    "id": "worse-promotion"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Midterm Lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
